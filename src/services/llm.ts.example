/**
 * llm.ts — Single gateway for all LLM (GPT-4o mini) calls.
 *
 * ╔══════════════════════════════════════════════════════════════╗
 * ║  SECURITY: All sensitive values (URL, key) are stored as   ║
 * ║  XOR-encrypted byte arrays. They are NEVER present as      ║
 * ║  readable strings in the compiled JavaScript output.        ║
 * ║                                                             ║
 * ║  Layer 1 — XOR encryption at rest                          ║
 * ║  Layer 2 — Webpack minification + variable mangling        ║
 * ║  Layer 3 — Per-request signature headers                   ║
 * ╚══════════════════════════════════════════════════════════════╝
 *
 * SETUP:
 *   1. Copy this file to `llm.ts`
 *   2. Run the encode helper to generate your own encrypted byte arrays:
 *        node -e "const s = require('./src/utilities/secrets'); console.log(s.xorEncode('YOUR_URL'));"
 *   3. Replace the XXXXX arrays below with the output.
 */
import axios from 'axios';
import { xorDecode, generateRequestSignature } from '../utilities/secrets';

// ── Encrypted endpoint fragments (decoded only at call-time) ───────────
// Replace these placeholder arrays with your own XOR-encoded values.
// Use xorEncode() from secrets.ts to compute them.
const _H: number[] = [/* XXXXX — xorEncode('https://your-azure-function.azurewebsites.net') */];
const _P: number[] = [/* XXXXX — xorEncode('/api/YourEndpoint') */];
const _K: number[] = [/* XXXXX — xorEncode('your-function-key') */];

/** Lazily resolved endpoint — decoded once, then cached. */
let _cachedUrl: string | null = null;
function _resolveEndpoint(): string {
    if (!_cachedUrl) {
        _cachedUrl = `${xorDecode(_H)}${xorDecode(_P)}?code=${xorDecode(_K)}`;
    }
    return _cachedUrl;
}

/**
 * Call GPT-4o mini via Azure Function gateway.
 *
 * @param userMessage — The user's input / content to process.
 * @param systemPrompt — Instructions that guide the LLM's behaviour.
 * @param timeoutMs — Request timeout in milliseconds (default 30 000).
 * @returns The LLM's text response, or `null` on failure.
 */
export async function callLLM(
    userMessage: string,
    systemPrompt: string,
    timeoutMs = 30_000,
): Promise<string | null> {
    try {
        const combinedPrompt = `${systemPrompt}\n\nUser: ${userMessage}`;
        const { signature, timestamp } = generateRequestSignature();

        console.log('[OCLite LLM] Sending to GPT-4o mini via Azure gateway…');

        const response = await axios.post(
            _resolveEndpoint(),
            { prompt: combinedPrompt },
            {
                headers: {
                    'Content-Type': 'application/json',
                    'X-OCLite-Sig': signature,
                    'X-OCLite-TS': timestamp.toString(),
                },
                timeout: timeoutMs,
            },
        );

        const body = response.data;
        const content = (
            body.result ??
            body.response ??
            body.message ??
            body.choices?.[0]?.message?.content ??
            ''
        ).trim();

        if (content) {
            console.log('[OCLite LLM] Response:', content.substring(0, 120));
            return content;
        }

        console.warn('[OCLite LLM] Empty response from GPT-4o mini');
    } catch (error: any) {
        console.error(
            '[OCLite LLM] Call failed:',
            error.response?.status,
            error.response?.data || error.message,
        );
    }

    return null;
}
